Merge skipgram branch
Change prob model to just model prob of word in topic
Add super simple explanatory models
Hook up RTD to docstrings
Remove spacy dep

Add an example script with 20 newsgroups -- LDA
    Add visualization for topic-word
    Add examples of specific documents

Add an example script with wiki word2vec data -- w2v
Add an example script with PTB word2vec data -- w2v
Add an example script with HN data -- LDA & w2v & ratings
Add better README
Add model saving
Add model predicting

Add bigramming
Change EmbedMixture naming to possible values and n latent factors
Print out topics while training
Add doctets to lda2vec main classes
Randomize chunking order on fit
Add loss tracking and reporting classes to code
Finish filling out docstrings
Add multiple targets for one component
Implement skipgram contexts
    Prevent mixing between documents
Add temperature to perplexity measurements
Add temperature to viz
Add convergence criterion
Add visualization for biclustering topics

Add docs on:
    Installation
    HN Tutorial
        Parse document into vector
        Setup LDA for document
        Mesure perplexity
        Visualize topics
        Add supervised component
        Mesure perplexity
        Visualize topics
        Add another component for time
        Mesure perplexity
        Visualize topics
        Visualize topics, changing temperature
    Data formats
        Loose
        Compact
        Flat
    Contexts
        Categorical contexts
        Other contexts TBA
    Targets
        RMSE
        Logistic
        Softmax
    Advanced
        Options
            GPU
            Gradient Clipping
            Online learning, fraction argument
        Logging progress
        Perplexity
        Model saving, prediction
        Dropout fractions

Nomenclature
    Categorical Feature
        Each category in set has n_possible_values
        Each feature has n_latent_factors
        Each feature has a single target
    Components
        Each component defined total number of documents and number of topics
        Each component may also have supervised targets

Done:
    Add BoW mode
    Add logger
    Add fake data generator
    Add perplexity measurements
    Add tracking utility
    Add utilities for converting corpora
    Put license
    Add masks / skips / pads
    Add reindexing on the fly
    Convert docstrings to numpy format
    Implement corpus loose to dense and vice versa
    Add fit function for all data at once
    Add CI & coverage & license icons
    Add readthedocs support
    Add examples to CI
    Add dropout
    Change component naming to 'categorical feature'
    Add linear layers between input latent and output context
